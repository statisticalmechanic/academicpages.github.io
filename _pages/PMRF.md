---
layout: archive
title: "PMRF Profile"
permalink: /PMRF/
author_profile: true
---

My name is Aanjaneya Kumar and I am a PhD student at the [Indian Institute of Science Education and Research Pune](http://www.iiserpune.ac.in/) working under the supervision of [Prof. M. S Santhanam](http://www.iiserpune.ac.in/~santh/). My primary interest is in obtaining insight into practically relevant problems, which could arise in various fields including (but not restricted to) physics, biology, and the social sciences, by first formulating them as mathematical models and then analyzing them using tools from Statistical Physics, Graph Theory and Game Theory. Here is a link to my [CV](https://drive.google.com/file/d/1NmDan2AIuPYDvGjsz_qBM_EWmpGll8Pb/view?usp=sharing).

A unifying theme of my interests comes from the guiding philosophy behind the several recent developments in the field of Nonequilibrium Statistical Physics. Statistical Physics is a branch of science that deals with systems comprising of a large number of units where we attempt to better understand the phenomena that emerge out of their interactions - many of which are not accessible through reductionist treatments. Systems that are in equilibrium obey the laws of Equilibrium Statistical Physics − a subject whose tools are mature and well developed. However, unlike its equilibrium counterpart, Nonequilibrium Statistical Physics does not have an overarching formalism. But in the last three decades, this field has seen a substantial amount of progress. A significant portion of this recent progress has come through the adoption of a kinetic approach. The idea of this approach is to study simple stochastic models specified by dynamical rules which capture the essence of the real process that we are trying to describe. Once the model and its dynamical rules are established, the next step is to critically analyze these simple models, and through this analysis, uncover the new features that the model could possibly tell us about the real process at hand.
The general philosophy described above, in fact, goes much beyond Statistical Physics and can be thought of as a guiding principle for fruitful research across disciplines. I try my best to keep this approach in mind while tackling research problems. 

As a Prime Minister's Research Fellow, I aim to carry out collaborative, interdisciplinary research in the following areas:


# Extreme Events

Extreme events, broadly defined as those events whose numerical values show a pronounced deviation from their typical values and exceed some predefined threshold, are ubiquitous and they occur in a wide variety of natural, social and engineering systems. Not surprisingly, the study of extreme events and systemic failures has received a lot of recent research attention. Starting from market crashes and power blackouts, to extreme climate events and internet breakdown -- extreme events can lead to disastrous consequences in the systems they occur in and severely disrupt their functioning. To this end, a growing body of literature is focused towards building a theoretical framework to analyze such rare events. The classical extreme value statistics is nearly a century old and more recently, advances in large deviation theory have improved our understanding of extreme events. There also has been an interesting line of work, which has aimed to understand how extreme events take place in networked systems. In my [first project](https://aip.scitation.org/doi/10.1063/1.5139018) as a PhD student, I explored the problem of extreme events taking place on the *edges* of a network, and showed that they show strikingly different statistics than extreme events taking place on the *nodes* of a network, and also explored the correlations between successive extreme events. However, while the examples in which extreme events are usually brought up have a negative connotation to them, extreme events in the form of rare binding events form the basis for many bio-chemical reactions essential for life. 

Several examples of molecular activation within cellular microdomains rely on the binding of diffusing molecules to specific target proteins. Additionally, there exist several instances where activation is only possible when at least a certain number of molecules are bound to the target. Classic examples of such \emph{threshold activated processes} include vesicular transmitter release in neurons which is initiated upon the accumulation of five calcium ions at a small target underneath a vesicle, and the saturation of a hemoglobin molecule, that happens when four oxygen molecules. Another class of threshold activated processes include damage accumulation, where a system ages over time and undergoes undergoes small-scale failure events which are potentially followed by repair events. While repair events can decrease the net accumulated damage, if the net damage crosses for a threshold, it can lead to irreversible changes in the system. While examples of this class of threshold crossing processes extend well beyond the walls of a cell, and include several engineering systems, a prototypical example can be made of the 'decision' to undergo apoptosis as a cellular response to accumulated damage. In this case, however, the threshold is not a fixed quantity.  

Grebekov introduced the problem of [impatient particles](https://aip.scitation.org/doi/10.1063/1.4996395) for an improved modelling of threshold activated processes, which deals with a scenario where *N* particles diffuse randomly in a confinement which contains an adsorbing trap. Particles which are incident on the trap are bound to it for a while before unbinding and starting to diffuse again. An irreversible reaction is triggered when the number of particles bound to the adsorbing trap crosses a predefined threshold. Such processes are of extreme relevance in the context of several biological and chemical processes, but so far have remained analytically intractable. This prompted Lawley and Madrid to come up with an [elegant approximation](https://aip.scitation.org/doi/abs/10.1063/1.5098312) to the impatient particles problem in 2019. 

The model described above have only dealt with the scenarios of perfect detection, i.e., as soon as the threshold is reached, the event is detected. In several scenarios, one would assume that the sensor, which detects whether the threshold has been reached or not, has a dynamics of its own, and intermittently switches between active and inactive states. How does this intermittency affect the reaction time statistics? We have been able to successfully answer this question by exploring a general class of threshold activated process with an intermittent sensor, modelled as a two-state Markov process. The results obtained in this project will be presented in an upcoming publication.

A major focus of my present research is to study extreme events in simple stochastic models that capture key features of practically relevant problems, and through my analysis, try to gain insight into the problem at hand. While the study of extreme events will form the bulk of my thesis (that's the plan), I keep my eyes open for new learning opportunities. Some other areas that seem fascinating to me are:  


# Interacting Algorithms

Human decision making is increasingly delegated to algorithms in a variety of contexts, ranging from high-frequency financial trading to online bot ecosystems in social media, to the so called “Internet of things”. Together with enormous potential for economic growth, such a paradigmatic change brings considerable uncertainty. Indeed, a number of situations have already exposed the unintended consequences that may emerge from systems of algorithms interacting in a largely unsupervised manner. A key interest for me in this project is to be able to build a formal understanding of the conditions under which the behaviour of such autonomous systems may result in large scale failures or, more generally, unintended and undesirable consequences. 


# Evolutionary Game Theory

Apart from helping us understand biodiveristy, the theory of evolution has given us insight into the evolution of cooperation and languages, as well as the dynamics of virus infections and human cancer. The simple underlying idea behind the theory is that different features among individuals (physical appearance, behaviours, strategies) lead to different (appropriately defined) fitnesses, which eventually leads to a higher relative representation of individuals, whose traits were deemed evolutionarily fit in the past, and hence those traits were successfully passed on to later generations. Concepts from game theory, which were introduced to study rational self-interested agents, have now been able to successfully give a mathematical structure to the theory of evolution, which allows us to probe several questions. A bunch of (related) questions that I am interested in are: Even with the advent of technology, while the facts maybe just a careful Google search away, why does fake news persist for long in our society? Why do retracted papers continue to be cited in scientific literature? Is there a way in which we could combat misinformation?






